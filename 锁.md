条件变量
信号量
互斥锁(mutex) 自旋锁 可重入/不可重入 

mutex 的 lock 可以上锁，但是不建议直接调用，因为会忘记调用 unlock ，推荐使用 std::lock_guard(`std::lock_guard<std::mutex> lock(mtx);`)

而 std::unique_lock 则相对于 std::lock_guard 出现的，std::unique_lock 更加灵活， std::unique_lock 的对象会以独占所有权（没有其他的 unique_lock 对象同时拥有某个 mutex 对象的所有权） 的方式管理 mutex 对象上的上锁和解锁的操作。所以在并发编程中，推荐使用 std::unique_lock。`std::unique_lock<std::mutex> lock(mtx);`

std::lock_guard 不能显式的调用 lock 和 unlock， 而 std::unique_lock 可以在声明后的任意位置调用， 可以缩小锁的作用范围，提供更高的并发度。

如果你用到了条件变量 std::condition_variable::wait 则必须使用 std::unique_lock 作为参数。(因为条件变量在wait时会进行unlock再进入休眠, lock_guard并无该操作接口)

mutex 成员函数
- lock()，调用线程将锁住该互斥量。线程调用该函数会发生下面 3 种情况：   
    (1). 如果该互斥量当前没有被锁住，则调用线程将该互斥量锁住，直到调用 unlock之前，该线程一直拥有该锁。   
    (2). 如果当前互斥量被其他线程锁住，则当前的调用线程被阻塞住。   
    (3). 如果当前互斥量被当前调用线程锁住，则会产生死锁(deadlock)。
- unlock()， 解锁，释放对互斥量的所有权。
- try_lock()，尝试锁住互斥量，如果互斥量被其他线程占有，则当前线程也不会被阻塞。线程调用该函数也会出现下面 3 种情况:
    (1). 如果当前互斥量没有被其他线程占有，则该线程锁住互斥量，直到该线程调用 unlock 释放互斥量。   
    (2). 如果当前互斥量被其他线程锁住，则当前调用线程返回 false，而并不会被阻塞掉。   
    (3). 如果当前互斥量被当前调用线程锁住，则会产生死锁(deadlock)。


-----

内存模型（memory model），其作用就是规定了各种不同的访问共享内存的方式，不同的内存模型，既需要编译器的支持，也需要硬件CPU的支持。
- Sequential Consistency (顺序一致性），简称 SC ，最直白、简单的一种内存模型。
    - 每个处理器的执行顺序和代码中的顺序（program order）一样。
    - 所有处理器都只能看到一个单一的操作执行顺序。
- 全存储排序（Total Store Ordering），简称TSO
    - 有一些CPU架构，在处理核心中增加写缓存，一个写操作只要写入到本核心的写缓存中就可以返回。由于还没有写到主存，可能会出现不一致的问题。
- 松弛型内存模型（Relaxed memory models）
- 弱序一致性模型（WO, Weak-order model）
- 处理器一致性模型（PC, Processor-consistency model）
- 松弛一致性模型（RC, Release consistency model）
- PSO一致性模型（Partial Store Ordering）



编译器优化
CPU out-of-order执行
CPU Cache不一致性


编译器将代码编译为机器码，根据自己的优化，会进行机器码重排。

CPU 执行机器码，根据自己的优化，会进行指令重排。

单线程的代码也会存在上述两种重排，但是都是在合理范围内。例如不会将 if 语句的逻辑重排到判断之外。
例如代码:
```c++
// 假设 a = 0, b = 0
a++;            // 1
b++;            // 2
```
对于第 1 行的代码，编译成汇编，对应 3 条指令:
```
move(从内存到寄存器)
add
move(从寄存器到内存)
```
在多线程中，可能存在：A 线程执行到第 2 条指令，B 线程开始执行第 1 条指令，这个时候 B 就没有看到 A 的执行，导致 A 和 B 的结果都是 1 。
所以引入原子操作，将那 3 条汇编语句变为一个整体，别的线程无法在其执行期间访问，也就是起到了锁的作用。
仔细思考一下，我们对 x 进行原子操作的地方，其实锁定了线程间的关系，是一个同步点（多线程中，在第一个执行原子操作的线程之后，其余线程执行到同样的 x 原子操作地方，一定是可以看到结果的）。那么，以这个点为基准，我们就可以得出两个线程当中其它指令执行先后顺序关系。如果第 2 行代码确定是在 第 1 行代码 执行之前执行，那么在 `a++;` 之后，所有线程都能看到 b 这个变量的修改了。

但第 2 行的代码，到底是在第 1 行之前还是之后执行嘞？这个是不知道的，因为重排了。

> 所谓的 memory order ，其实就是限制编译器以及 CPU 对单线程当中的指令执行顺序进行重排的程度（此外还包括对cache的控制方法）。这种限制，决定了以atom操作为基准点（边界），对其之前的内存访问命令，以及之后的内存访问命令，能够在多大的范围内自由重排（或者反过来，需要施加多大的保序限制）。从而形成了6种模式。它本身与多线程无关，是限制的单一线程当中指令执行顺序。但是（合理的）指令执行顺序的重排在单线程环境下不会造成逻辑错误而在多线程环境下会，所以这个问题的目的是为了解决多线程环境下出现的问题。

包括同步原语也是，本质都是对于某个点之前或者之后的内存访问，进行保序限制。







acquire 对应的屏障，只允许代码往下方向移动，而 release 则只允许上方向移动。

memory_order_relaxed: 属于 松散 模型。只保证操作的原子性，不影响这个同步点前后的其它内存操作。这是原子操作中最宽松的内存顺序。

memory_order_acquire: 属于 获取发布 模型。提供 read acquire 的语意，适用于 atomic load 操作。read acquire 语意会阻止原子操作之后的所有读和写被重排到原子操作之前。
```c++
A.load(std::memory_order_acquire);
B = 42;  // 不可能被重排到 A.load(std::memory_order_acquire); 之前
```
memory_order_release: 属于 获取发布 模型。提供 write release 语意，适用于 atomic store 操作。write release 语意会阻止原子操作之前的所有读和写被重排到原子操作之后。
```c++
B = 42; // 不可能被乱序到 A.store(1, std::memory_order_release); 之后
A.store(1, std::memory_order_release);
```
memory_order_consume: 属于 获取发布 模型。比 memory_order_acquire 弱一些的语意。它会阻止原子操作之后 **有依赖关系** 的读写操作被重排到原子操作之前。 
根据 [文档](https://en.cppreference.com/w/cpp/atomic/memory_order) 描述，暂不推荐使用。
> The specification of release-consume ordering is being revised, and the use of memory_order_consume is temporarily discouraged.(since C++17)

memory_order_acq_rel: 属于 获取发布 模型。对一个 load-modify-store 的原子操作施加 read acquire 和 write release 的内存顺序限制。

memory_order_seq_cst: 属于 顺序一致 模型。最严格的内存顺序，使用该默认模型的操作，上移下移都不被允许:
- 对于 atomic load，它会执行 acquire 语意。
- 对于 atomic store，它会执行 release 语意。
- 对于 load-modify-store，它会执行 acquire-release 语意。
- 除此之外，它还保证，所有线程观察到的所有原子变量的修改顺序是一致的。